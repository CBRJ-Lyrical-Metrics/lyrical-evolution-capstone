{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a54c8f7-aa1f-4305-bbf3-62fb05b75fbc",
   "metadata": {},
   "source": [
    "TITLE\n",
    "subtitle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49eb0c4-37d7-45cc-979b-57baaf3d0d2e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c102d20-adbd-44b0-a0fc-0062cacb04eb",
   "metadata": {},
   "source": [
    "**Capstone Project & Final Report Created By:**\n",
    "\n",
    "Ben Smith, Chris Teceno, Jerry Nolf & Rachel Robbins-Mayhill\n",
    "Codeup   |   Innis Cohort   |   June 2022  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5418c18d-08f6-47d1-8acf-5ecc4cbd04cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a8499-ba91-4a83-89c6-67dd43412f15",
   "metadata": {},
   "source": [
    "## Project Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ea423-ffff-4db2-b9a5-cd732dd36094",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55c6df-51d2-412e-adce-1daa9ca98119",
   "metadata": {},
   "source": [
    "## Initial Thoughts & Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142d940-b385-4db4-b002-1d76ab647b73",
   "metadata": {},
   "source": [
    "## Initial Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b0078-9645-445d-9dec-996ac6aa654e",
   "metadata": {},
   "source": [
    "## Key Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff086dd-8e1c-41b6-89a0-7f4795d490e3",
   "metadata": {},
   "source": [
    "=========================================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f447ae0-d3ba-4e65-9e65-923a31f642cb",
   "metadata": {},
   "source": [
    "## I. ACQUIRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac72be3-1478-4f30-8653-a08976cab5a6",
   "metadata": {},
   "source": [
    "### Note about imports: \n",
    "Imports for this project are added in the sections in which they are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a8a76-8a52-468b-84d5-13ad0a952e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for acquisition\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import wrangle\n",
    "import model\n",
    "from env import github_token, github_username\n",
    "\n",
    "# import for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "\n",
    "# import to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b3645-39b5-422e-8cf4-e884a2004574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire data from .json saved and processed using functions found in wrangle.py\n",
    "df = pd.read_json(\"data.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3880d05-efc6-46ab-972a-8c76a99d3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain number of columns and rows for original dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd63d50-ff49-481a-8a6e-ebefdec84ba3",
   "metadata": {},
   "source": [
    "### The Original DataFrame Size: ____ rows, or documents, and ____ columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ce5ea-d032-4f7d-8c2d-dc6b6375d8b8",
   "metadata": {},
   "source": [
    "=========================================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0896e47-ee98-4192-9cb0-f79b187d5658",
   "metadata": {},
   "source": [
    "## II. PREPARE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9df564-01cc-463b-96a6-8536629a9e95",
   "metadata": {},
   "source": [
    "After data acquisition, the table was analyzed and cleaned to facilitate functional exploration and clarify variable confusion. The preparation of this data can be replicated using the prep_data  function saved within the prepare.py file inside the 'NLP-Project' repository on GitHub. The function takes in the original data.json dataframe and returns it with the changes noted below.\n",
    "\n",
    "**Steps Taken to Clean & Prepare Data:**\n",
    "\n",
    "- Basic Cleaning: \n",
    "    - Make all text lowercase\n",
    "    - Normalize, encode, and decode to remove accented text and special characters\n",
    "    - Tokenize strings to break words and punctuation into discrete units\n",
    "    - Stem and Lemmatize words to acquire base words\n",
    "    - Remove stopwords\n",
    "    - Rename columns\n",
    "---   \n",
    "- Address missing values, data errors, unnecessary data, and unclear values:\n",
    "    - Replace Jupyter Notebook values with Python after manually verifying most Jupyter Notebook entires used the Python programming language \n",
    "    - Drop missing values to prevent impediments in exploration and modeling: 9 documents/observations that had null values in the language column \n",
    "    - Drop all rows where README length was 0\n",
    "    - Total dropped documents = 32\n",
    "---    \n",
    "- Create feature engineered columns:\n",
    "    - unique words\n",
    "    - character count\n",
    "    - word count\n",
    "    - unique word count\n",
    "    - most common word count (2nd, 3rd, 4th, 5th most common)\n",
    "    - unique bigram count\n",
    "    - count of bigrams unique to each language in train set(this is done by creating a new column for each language)\n",
    "    \n",
    "---\n",
    "- Split corpus into train, validate, and test samples\n",
    "\n",
    "**Note on Missing Value Handling:**\n",
    "The missing value removal equated to removing 9 observations/documents, which was about 9\\% of the data set. It still left a substantial number of observations above the minimum expectation of 100. If given more time with the data, it is recommended to investigate other ways to impute the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b3c41-a336-4a8c-9777-c13ff07c28ef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee80dea-08b3-4064-adcf-513ab910b2d5",
   "metadata": {},
   "source": [
    "## Results of Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c4894-1f7c-4684-8b22-81b119ad2ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for prepare\n",
    "import prepare\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from time import strftime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c382de0-355d-40e6-9afe-137f3c86888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the data preparation observations and tasks to clean the data using the prep_data function found in the prepare.py\n",
    "df = prepare.prep_data(df)\n",
    "# view first few rows of dataframe\n",
    "# obtain the number of rows and columns for the updated/cleaned dataframe \n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f06a2-40f7-49ea-b3b2-502d3a90b253",
   "metadata": {},
   "source": [
    "## Prepared DataFrame Size: 134 rows, or documents, and 13 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad099ea-da58-4d5c-81d7-b391b4449579",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fdb06a-f042-4b96-8fda-bf90f16f0227",
   "metadata": {},
   "source": [
    "### PREPARE - SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa98112-1a01-4d46-bfe5-70db5d26156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c20745-cd3b-4686-a502-99981315e1d0",
   "metadata": {},
   "source": [
    "After preparing the corpus, it was split into 3 samples; train, validate, and test using:\n",
    "\n",
    "- Random State: ______\n",
    "- Test = 20% of the original dataset\n",
    "- The remaining 80% of the dataset is divided between valiidate and train\n",
    "    - Validate (.30*.80) = 24% of the original dataset\n",
    "    - Train (.70*.80) = 56% of the original dataset\n",
    "    \n",
    "The split of this data can be replicated using the split_data function saved within the prepare.py file inside the [_____](_________) repository on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687cb248-9647-41c5-9d50-30a4afa44e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train, validate, and test using the split_data function found in the prepare.py\n",
    "train, validate, test = prepare.split_data(df)\n",
    "# obtain the number of rows and columns for the splits\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c0e03e-2952-4eb6-9d44-54a5a04b8bf4",
   "metadata": {},
   "source": [
    "=========================================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c78fe-d835-4aa1-ab27-80c23b51faf5",
   "metadata": {},
   "source": [
    "## III. EXPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd7468a-7db3-4a6c-ba59-ca948831622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for data visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from matplotlib import style\n",
    "from wordcloud import WordCloud\n",
    "import explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ece60b-5838-41ee-ac9b-577d3db57fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Universal Visualization Formatting\n",
    "\n",
    "# determine figure size\n",
    "plt.rc('figure', figsize=(20, 8))\n",
    "# determine font size\n",
    "plt.rc('font', size=15)\n",
    "# determine style\n",
    "plt.style.use('seaborn-deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e368cfc-c8db-4375-9436-087118ad07ca",
   "metadata": {},
   "source": [
    "After acquiring and preparing the corpus, exploration was conducted. All univariate exploration was completed on the entire cleaned corpus in the workbook for this project. For the purpose of the final report, only the target variable will be displayed in order to reduce noise and provide focused context for the project. Following univariate exploration, the split sets (train, validate, and test samples) were utilized thorugh modeling, where only the train set was used for bivariate and multivariate exploration to prevent data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b897a71-03f3-440f-a53c-7c5ca636dc48",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1854228a-7ff2-41dd-9e88-b55feba10cb3",
   "metadata": {},
   "source": [
    "### UNIVARIATE EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617865e3-742d-4be4-8f35-25cc1a5d5d8e",
   "metadata": {},
   "source": [
    "#### UNIVARIATE EXPLORATION of TARGET VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f5ff97-3cea-44a4-935a-7d2cf7ac42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create visualization\n",
    "df.language.value_counts().plot(kind='pie', y='Language', autopct=\"%1.1f%%\")\n",
    "# remove y axis label\n",
    "plt.ylabel(None)\n",
    "#add title\n",
    "plt.title('Top 4 Programming Langauges Across Corpus by Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e7208-151f-4d23-89dd-c06b8b02a4b6",
   "metadata": {},
   "source": [
    "#### OBSERVATIONS: \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4497c72-55d0-49eb-be38-154f2edf0a13",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c18e44d-ab8b-4cd3-af33-6388dd07862f",
   "metadata": {},
   "source": [
    "### EXPLORATION QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa631c3e-d91c-4717-b4cc-01f09def4632",
   "metadata": {},
   "source": [
    "All bivariate exploration was conducted on the train corpus to prevent data leakage. The initial questions and univariate exploration guided the bivariate exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9502d911-af97-483e-a1d5-349aea49a78b",
   "metadata": {},
   "source": [
    "#### EXPLORE QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888ede95-8e60-4d69-a6b0-a2b317559668",
   "metadata": {},
   "source": [
    "### QUESTION 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa39be-a1af-4ba8-89fb-21175c3d9c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2dc44-bf0e-483a-be7f-48cdf293df70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93106b-1655-45ca-95f8-912ab18e5910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f22a5b-4bf8-48fe-b613-1031a3ffcb57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a35ce-6efe-49a5-9e1b-2fa9f52d04e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c456be1-eb72-47a7-b705-67edb07d26e4",
   "metadata": {},
   "source": [
    "=========================================================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15980c0-808c-448b-9a74-6fb25fff882e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53b8ebc6-10c5-4182-9d63-0e4d761931d7",
   "metadata": {},
   "source": [
    "## IV. MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d6649-e624-4553-a888-6d541bc4abed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38284848-c794-43c9-8fa2-7c38be8437e5",
   "metadata": {},
   "source": [
    "=========================================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f62750-5420-47d4-92e5-67b1759ff80d",
   "metadata": {},
   "source": [
    "## V. CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca57c2-01a1-450b-99b8-4604562e3865",
   "metadata": {},
   "source": [
    "=========================================================================================================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

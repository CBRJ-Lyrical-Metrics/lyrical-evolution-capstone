{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6000f56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jerrynolf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jerrynolf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Unicode, Regex, json for text digestion\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "# Time formatting\n",
    "from time import strftime\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# nltk: natural language toolkit -> tokenization, stopwords\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer as stemmer\n",
    "# nltk.download('stopwords')\n",
    "import nltk.sentiment\n",
    "sia = nltk.sentiment.SentimentIntensityAnalyzer()\n",
    "\n",
    "# Quieeet!!! Y'all can't stop me now...\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9740e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import draft_prepare as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5ce7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23762, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('songs_0526.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e551bcdb",
   "metadata": {},
   "source": [
    "### Preparing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47098db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>character_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>#1</td>\n",
       "      <td>Nelly</td>\n",
       "      <td>2001-10-20</td>\n",
       "      <td>#1 LyricsUh uh uh I just gotta bring it to the...</td>\n",
       "      <td>1 lyricsuh uh uh gotta bring attention dirty t...</td>\n",
       "      <td>1 lyricsuh uh uh gotta bring attent dirti that...</td>\n",
       "      <td>1 lyricsuh uh uh gotta bring attention dirty t...</td>\n",
       "      <td>2101</td>\n",
       "      <td>396</td>\n",
       "      <td>0.9901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>#9 Dream</td>\n",
       "      <td>John Lennon</td>\n",
       "      <td>1974-12-21</td>\n",
       "      <td>#9 Dream Lyrics[Verse 1] So long ago Was it in...</td>\n",
       "      <td>9 dream lyricsverse 1 long ago dream dream kno...</td>\n",
       "      <td>9 dream lyricsvers 1 long ago dream dream know...</td>\n",
       "      <td>9 dream lyricsverse 1 long ago dream dream kno...</td>\n",
       "      <td>875</td>\n",
       "      <td>152</td>\n",
       "      <td>0.9313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>#Beautiful</td>\n",
       "      <td>Mariah Carey Featuring Miguel</td>\n",
       "      <td>2013-05-25</td>\n",
       "      <td>#Beautiful Lyrics[Intro: Mariah Carey] Ah, ah,...</td>\n",
       "      <td>beautiful lyricsintro mariah carey ah ah youre...</td>\n",
       "      <td>beauti lyricsintro mariah carey ah ah your bea...</td>\n",
       "      <td>beautiful lyricsintro mariah carey ah ah youre...</td>\n",
       "      <td>973</td>\n",
       "      <td>180</td>\n",
       "      <td>0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>#SELFIE</td>\n",
       "      <td>The Chainsmokers</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>#SELFIE Lyrics[Verse 1] When Jason was at the ...</td>\n",
       "      <td>selfie lyricsverse 1 jason table kept seeing l...</td>\n",
       "      <td>selfi lyricsvers 1 jason tabl kept see look gi...</td>\n",
       "      <td>selfie lyricsverse 1 jason table kept seeing l...</td>\n",
       "      <td>985</td>\n",
       "      <td>190</td>\n",
       "      <td>0.8228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>#thatPOWER</td>\n",
       "      <td>will.i.am Featuring Justin Bieber</td>\n",
       "      <td>2013-04-06</td>\n",
       "      <td>#thatPOWER Lyrics[Instrumental break]  [Pre-Ch...</td>\n",
       "      <td>thatpower lyricsinstrumental break prechorus j...</td>\n",
       "      <td>thatpow lyricsinstrument break prechoru justin...</td>\n",
       "      <td>thatpower lyricsinstrumental break prechorus j...</td>\n",
       "      <td>1560</td>\n",
       "      <td>279</td>\n",
       "      <td>0.9978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       title                             artist        date  \\\n",
       "0           2          #1                              Nelly  2001-10-20   \n",
       "1           4    #9 Dream                        John Lennon  1974-12-21   \n",
       "2           5  #Beautiful      Mariah Carey Featuring Miguel  2013-05-25   \n",
       "3           6     #SELFIE                   The Chainsmokers  2014-03-15   \n",
       "4           7  #thatPOWER  will.i.am Featuring Justin Bieber  2013-04-06   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  #1 LyricsUh uh uh I just gotta bring it to the...   \n",
       "1  #9 Dream Lyrics[Verse 1] So long ago Was it in...   \n",
       "2  #Beautiful Lyrics[Intro: Mariah Carey] Ah, ah,...   \n",
       "3  #SELFIE Lyrics[Verse 1] When Jason was at the ...   \n",
       "4  #thatPOWER Lyrics[Instrumental break]  [Pre-Ch...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  1 lyricsuh uh uh gotta bring attention dirty t...   \n",
       "1  9 dream lyricsverse 1 long ago dream dream kno...   \n",
       "2  beautiful lyricsintro mariah carey ah ah youre...   \n",
       "3  selfie lyricsverse 1 jason table kept seeing l...   \n",
       "4  thatpower lyricsinstrumental break prechorus j...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  1 lyricsuh uh uh gotta bring attent dirti that...   \n",
       "1  9 dream lyricsvers 1 long ago dream dream know...   \n",
       "2  beauti lyricsintro mariah carey ah ah your bea...   \n",
       "3  selfi lyricsvers 1 jason tabl kept see look gi...   \n",
       "4  thatpow lyricsinstrument break prechoru justin...   \n",
       "\n",
       "                                          lemmatized  character_count  \\\n",
       "0  1 lyricsuh uh uh gotta bring attention dirty t...             2101   \n",
       "1  9 dream lyricsverse 1 long ago dream dream kno...              875   \n",
       "2  beautiful lyricsintro mariah carey ah ah youre...              973   \n",
       "3  selfie lyricsverse 1 jason table kept seeing l...              985   \n",
       "4  thatpower lyricsinstrumental break prechorus j...             1560   \n",
       "\n",
       "   word_count  sentiment  \n",
       "0         396     0.9901  \n",
       "1         152     0.9313  \n",
       "2         180     0.9981  \n",
       "3         190     0.8228  \n",
       "4         279     0.9978  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = p.clean_df(df, extra_words = [], exclude_words = [])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23494d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb7be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eecdfb2e",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50346dee",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9674b4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23762"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_lyrics = df['lemmatized']\n",
    "lemma_lyrics.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c314b357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize variables\n",
    "n_samples = 10_000\n",
    "n_features = 2_500\n",
    "n_topics = 10\n",
    "\n",
    "# Set up dataset to be fit\n",
    "dataset = lemma_lyrics\n",
    "# # \n",
    "# data_samples = dataset.data[:n_samples]\n",
    "\n",
    "# Use tf feature for LDA model\n",
    "tf_vectorizer  = CountVectorizer(max_df = 1.0, min_df = 1, \n",
    "                                 max_features = n_features)\n",
    "tf = tf_vectorizer.fit_transform(dataset)\n",
    "# Set up LDA\n",
    "lda = LatentDirichletAllocation(n_components = n_topics, max_iter = 10, random_state = 42)\n",
    "\n",
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc68c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8d07cb0",
   "metadata": {},
   "source": [
    "### Other methods using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b89f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16633, 7129)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_hold = train_test_split(df, test_size = .3, random_state = 42)\n",
    "X_train.shape[0], X_hold.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38ea7a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>character_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>1876</td>\n",
       "      <td>Baby, It's Cold Outside</td>\n",
       "      <td>Glee Cast</td>\n",
       "      <td>2010-12-25</td>\n",
       "      <td>Baby, It’s Cold Outside Lyrics[KURT &amp; (BLAINE)...</td>\n",
       "      <td>baby cold outside lyricskurt blaine really can...</td>\n",
       "      <td>babi cold outsid lyricskurt blain realli cant ...</td>\n",
       "      <td>baby cold outside lyricskurt blaine really can...</td>\n",
       "      <td>1163</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                    title     artist        date  \\\n",
       "1576        1876  Baby, It's Cold Outside  Glee Cast  2010-12-25   \n",
       "\n",
       "                                                 lyrics  \\\n",
       "1576  Baby, It’s Cold Outside Lyrics[KURT & (BLAINE)...   \n",
       "\n",
       "                                                  clean  \\\n",
       "1576  baby cold outside lyricskurt blaine really can...   \n",
       "\n",
       "                                                stemmed  \\\n",
       "1576  babi cold outsid lyricskurt blain realli cant ...   \n",
       "\n",
       "                                             lemmatized  character_count  \\\n",
       "1576  baby cold outside lyricskurt blaine really can...             1163   \n",
       "\n",
       "      word_count  \n",
       "1576         196  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1618956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = [word for word in nltk.word_tokenize(text) if (len(word) > 3 and len(word.strip('Xx/'))>2)]\n",
    "#     stems = [stemmer.stem(letter) for letter in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cefad853",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(tokenizer = tokenize, stop_words = 'english', \n",
    "                                max_df = .75, min_df = 50, max_features = 2_500)\n",
    "tf = tf_vectorizer.fit_transform(X_train.lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e806539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.04822434, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b8d03cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "get_names not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x6/9q2vjsz90nx_0lgx5gr8g33w0000gn/T/ipykernel_52336/3391491003.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: get_names not found"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895067da",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70880f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "261849a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85c831cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x6/9q2vjsz90nx_0lgx5gr8g33w0000gn/T/ipykernel_52336/3963349241.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd5f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

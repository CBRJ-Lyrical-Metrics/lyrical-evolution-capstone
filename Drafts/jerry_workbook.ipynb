{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6000f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typical Everydayers...\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Unicode, Regex, json for text digestion\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "# Time formatting\n",
    "from time import strftime\n",
    "# Make deepcopy\n",
    "import copy\n",
    "\n",
    "# Modeling help...\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# nltk: natural language toolkit -> tokenization, stopwords\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer as stemmer\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# sia = nltk.sentiment.vader.SentimentIntensityAnalyzer()\n",
    "\n",
    "# Import prepare\n",
    "import draft_prepare as p\n",
    "\n",
    "# Quieeet!!! Y'all can't stop me now...\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Let me see it AAAALLLL!!!\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "# set default style for charts\n",
    "plt.rc('figure', figsize=(13, 7))\n",
    "# plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e551bcdb",
   "metadata": {},
   "source": [
    "### Preparing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c23494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = p.model_clean(df)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5ce7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('songs_0526.csv', index_col = 0)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47098db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading csv file...\r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'songs_0526.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zb/3lg9b5xn3831bhkh23bd5bs00000gn/T/ipykernel_4666/686572703.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/codeup-data-science/song-lyrics-capstone/Drafts/draft_prepare.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(file, use_cache)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# read csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reading csv file...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;31m# clean data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'songs_0526.csv'"
     ]
    }
   ],
   "source": [
    "df = p.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = p.get_topics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecdfb2e",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fba184",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099cb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance\n",
    "cv = CountVectorizer(max_df = .95, min_df = 2, stop_words = 'english')\n",
    "\n",
    "# Fit and transform the lemmatized lyrics data\n",
    "cv_fit = cv.fit_transform(df.lyrics)\n",
    "\n",
    "print('\\nShape of the sparse matrix\\n')\n",
    "cv_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa529d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the instance for LDA\n",
    "lda = LatentDirichletAllocation(n_components = 20, random_state = 42)\n",
    "\n",
    "# Fit the vectorizer with the LDA\n",
    "lda.fit(cv_fit)\n",
    "\n",
    "print('Number of topics:', len(lda.components_))\n",
    "print('Number of columns of the LDA fit', len(lda.components_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8218fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = cv.get_feature_names()\n",
    "\n",
    "print('Length of feature names:', len(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd5e4e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display all topic categories in order to label them\n",
    "for ind, topic in enumerate(lda.components_):\n",
    "    print('-'*100)\n",
    "    print('Top 50 words in topic {}'.format(ind))\n",
    "    print('-'*117)\n",
    "    top_50 = topic.argsort()[-50:]\n",
    "    print([feature[i] for i in top_50], '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final df transforming cv_fit\n",
    "df_final = lda.transform(cv_fit)\n",
    "\n",
    "# Make copy to save original df \n",
    "df_new = copy.deepcopy(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nChecking the probability distribution of one text data belonging to the topic.\\n')\n",
    "\n",
    "print('Few words from 1st row:', df.lyrics[0][:88], '\\n')\n",
    "\n",
    "print('Probability distribution:', df_final[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = df_final[0][df_final[0].argmax()].round(2)\n",
    "\n",
    "print('Document belong to the topic', df_final[0].argmax(), 'with the probability of', prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ee194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic'] = df_final.argmax(axis = 1)\n",
    "\n",
    "# df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a072791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary with key as topic numbers and value as topic names\n",
    "topic_label = {0:'Jealousy', 1:'Affection', 2:'Breakup', 3:'Dance', 4:'Holiday', 5:'Nature', \n",
    "               6:'Spanish', 7:'Transcendental', 8:'Lost', 9:'Violence', 10:'Youth', 11:'Love', 12:'Heartache', \n",
    "               13:'Money', 14:'Affection', 15:'Sex', 16:'Dance', 17:'Good Vibes', 18:'Americana', 19:'Breakup'}\n",
    "\n",
    "# Mapping the dictionary with the dataframe to get the labels.\n",
    "df['topic_name'] = df['topic'].map(topic_label)\n",
    "\n",
    "# Head of the dataframe\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a551a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_topics(df):\n",
    "#     # Create an instance\n",
    "#     cv = CountVectorizer(max_df = .95, min_df = 2, stop_words = 'english')\n",
    "    \n",
    "#     # Fit and transform the lemmatized lyrics data\n",
    "#     cv_fit = cv.fit_transform(df.lyrics)\n",
    "\n",
    "#     # Create the instance for LDA\n",
    "#     lda = LatentDirichletAllocation(n_components = 20, random_state = 42)\n",
    "    \n",
    "#     # Fit the vectorizer with the LDA\n",
    "#     lda.fit(cv_fit)\n",
    "    \n",
    "#     # Pull feature names out and define as feature\n",
    "#     feature = cv.get_feature_names()\n",
    "    \n",
    "#     # Final df transforming cv_fit\n",
    "#     df_final = lda.transform(cv_fit)\n",
    "    \n",
    "# #     # Make copy to save original df \n",
    "# #     df_new = copy.deepcopy(df)\n",
    "    \n",
    "#     prob = df_final[0][df_final[0].argmax()].round(2)\n",
    "    \n",
    "#     # Assign the opics tp the dataframe\n",
    "#     df['topic'] = df_final.argmax(axis = 1)\n",
    "    \n",
    "#     # Creating a dictionary with key as topic numbers and value as topic names\n",
    "#     topic_label = {0:'Love', 1:'Kind Goodbye', 2:'Appeasing', 3:'Club', 4:'Country Life', 5:'Resentful Goodbye', \n",
    "#                    6:'Lost', 7:'Hard Times', 8:'Nature', 9:'Miracles', 10:'Money', 11:'Dance', 12:'Fun', \n",
    "#                    13:'Dance', 14:'Weekend', 15:'Transcendental', 16:'Sex', 17:'Summer', 18:'Spanish', 19:'Affection'}\n",
    "    \n",
    "#     # Mapping the dictionary with the dataframe to get the labels.\n",
    "#     df['topic_name'] = df['topic'].map(topic_label)\n",
    "# #     # Drop the unnecessary duplicate column\n",
    "# #     df = pd.concat([df, df_new['topic_name']], axis = 1)\n",
    "#     # Drop unnecessary column 'topic'\n",
    "#     df = df.drop(columns = ['topic'])\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ef06a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get_topics(df)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba4f69",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['sentiment'] = df.lyrics.apply(lambda msg: sia.polarity_scores(msg)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f019374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiments = sia\n",
    "# df[\"positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in df[\"lyrics\"]]\n",
    "# df[\"negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in df[\"lyrics\"]]\n",
    "# df[\"neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in df[\"lyrics\"]]\n",
    "# df['compound'] = [sentiments.polarity_scores(i)[\"compound\"] for i in data[\"lyrics\"]]\n",
    "\n",
    "# scores = df[\"lyrics\"].values\n",
    "# sentiment = []\n",
    "# for score in scores:\n",
    "#     if score >= 0.05 :\n",
    "#         sentiment.append('positive')\n",
    "#     elif score <= -0.05 :\n",
    "#         sentiment.append('negative')\n",
    "#     else:\n",
    "#         sentiment.append('neutral')\n",
    "# data[\"sentiment_class\"] = sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8152591",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88017ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    '''\n",
    "    This function takes in a data frame and splits it appropriately in order\n",
    "    to return a train with 56%, validate with 24%, and test with 20% of the\n",
    "    original data frame.\n",
    "    '''\n",
    "    # Split with train being 80% and test being 20%. Stratify on target.\n",
    "    train, test = train_test_split(df, test_size = .2, random_state = 123)\n",
    "    # Split the remaining train into 70% train and 30% validate.\n",
    "    train, validate = train_test_split(train, test_size = .3, random_state = 123)\n",
    "    # Spiltting results in a split with 56% train, 24% validate, and 20% test data from original\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43445a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = split_data(df)\n",
    "train.shape[0], validate.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # What song has the lowest sentiment?\n",
    "# train.sort_values(by = ['sentiment'], ascending = True).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e37fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # What song has the highest sentiment?\n",
    "# df.sort_values(by = ['sentiment'], ascending = False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfcf136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(by = ['topic_name'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dbc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the average sentiment for each topic?\n",
    "df.groupby(['topic_name']).mean()['sentiment'].sort_values(ascending = False).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "# Most popular topics...\n",
    "def topic_popularity(df):\n",
    "    df.topic_name.value_counts().plot(kind = 'bar')\n",
    "    plt.title('Billboard Hot 100 Topic Popularity 1958-Present')\n",
    "    plt.xlabel('Topic Descriptors')\n",
    "    plt.xticks(rotation = 35, ha = 'right')\n",
    "    plt.ylabel('Song Topic Count')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ceb697",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_popularity(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6adc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most popular topics...\n",
    "def topic_popularity(df):\n",
    "    colors =(\n",
    "    '#ec1c34', #(red)\n",
    "    '#fc9d1c', #(orange)\n",
    "    '#fbdb08', #(yellow)\n",
    "    '#2dace4', #(blue)\n",
    "    '#69b138', #(green)\n",
    "    '#1f1e1b' #(black)\n",
    "    )\n",
    "    df.topic_name.value_counts().plot(kind = 'bar', color = colors, figsize = (13,7))\n",
    "    # plt.figure(figsize=(10,5))\n",
    "    plt.title('Billboard Hot 100 Topic Popularity 1958-Present', fontsize = 20)\n",
    "    plt.xlabel('Topic Descriptors', fontsize = 18)\n",
    "    plt.xticks(rotation = 35, ha = 'right', fontsize = 14)\n",
    "    plt.ylabel('Song Topic Count', fontsize = 18)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4729340",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topic_popularity(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What topics are most common in each decade?\n",
    "df.groupby(['topic_name', 'decade']).size()\\\n",
    "                                    .unstack()\\\n",
    "                                    .sort_values(by = 'topic_name', \n",
    "                                                 ascending = False).T\\\n",
    "#                                     .plot(kind = 'bar', ec = 'black')\n",
    "# plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4af3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f31d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "def all_topics_Prevalence(df):   \n",
    "    ax = sns.countplot(data = df, x = 'decade', hue = 'topic_name', ec = 'black')\n",
    "    plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0.)\n",
    "    plt.title('Topics\\' Prevalence Over the Decades')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation=25)\n",
    "    plt.xlabel('Decade of Song')\n",
    "    plt.ylabel('Song Count')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_Prevalence(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d795c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Billboard Colors\n",
    "def all_topics_Prevalence(df):   \n",
    "    ax = sns.countplot(data = df, x = 'decade', hue = 'topic_name', ec = 'black', palette = palette)\n",
    "    plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0.)\n",
    "    plt.title('Topics\\' Prevalence Over the Decades')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation=25)\n",
    "    plt.xlabel('Decade of Song')\n",
    "    plt.ylabel('Song Count')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_Prevalence(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde73f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Billboard Colors\n",
    "# make a copy\n",
    "    df2 = df.copy()\n",
    "    df2 = df2.set_index('date')\n",
    "    # add a column to the dataframe where any topic that is a relationship topic is gathered and all \n",
    "\n",
    "    ax = df2.groupby('topic_name').resample('Y').size().unstack(0).rolling(5).mean()\\\n",
    "                                      .apply(lambda row: row / row.sum(), axis=1).plot(kind = 'line', linewidth = 3, cmap = cmap)\n",
    "    # move the legend outside\n",
    "    plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0.)\n",
    "    plt.xlim(pd.to_datetime('1960'), pd.to_datetime('2021'))\n",
    "#     plt.ylim()\n",
    "    plt.title('Prevalence of Topics in Lyrics')\n",
    "    plt.xlabel('Year')\n",
    "    plt.xticks(rotation = 25)\n",
    "    plt.ylabel('Percentage of Songs')\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=None, symbol='%', is_latex=False))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58715b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the top 5 topics for each decade?\n",
    "train.groupby(['decade']).topic_name.value_counts().head(19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.topic_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create a variable that stores a list relationship topics\n",
    "# relationships = ['affection','breakups','love', 'breakup', \n",
    "#                  'sex', 'heartache', 'jealousy']\n",
    "# # make a copy\n",
    "# train2 = train.copy()\n",
    "# #add a column to the dataframe where any language not in the top five is represented by 'other'\n",
    "# train2['relationship_topics'] = np.where(train2.topic_name.isin(relationships), train2.topic_name, 'other')\n",
    "# train2 = train2.loc[train2['relationship_topics'] != 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "def relationship_bar(df):   \n",
    "    # create a variable that stores a list relationship topics\n",
    "    relationships = ['affection','breakups','love', 'breakup', \n",
    "                     'sex', 'heartache', 'jealousy']\n",
    "    # make a copy\n",
    "    df2 = df.copy()\n",
    "    # add a column to the dataframe where any topic that is a relationship topic is gathered and all \n",
    "    # others are represented by 'other'\n",
    "    df2['relationship_topics'] = np.where(df2.topic_name.isin(relationships), df2.topic_name, 'other')\n",
    "    # drop anything that isn't a relationship topic\n",
    "    df2 = df2.loc[df2['relationship_topics'] != 'other']\n",
    "    df2.groupby('decade').relationship_topics.value_counts(normalize = True).unstack().plot(kind = 'bar', width = 1, ec = 'black')\n",
    "    plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0.)\n",
    "    plt.title('Relationship Topics\\' Prevalence Over the Decades')\n",
    "    plt.xlabel('Decade of Song')\n",
    "    plt.ylabel('Song Topic Count')\n",
    "    plt.show()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b68a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_bar(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab06dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable that stores a list relationship topics\n",
    "relationships = ['affection','breakups','love', 'breakup', \n",
    "                 'sex', 'heartache', 'jealousy']\n",
    "# make a copy\n",
    "df2 = df.copy()\n",
    "df2 = df2.set_index('date')\n",
    "# add a column to the dataframe where any topic that is a relationship topic is gathered and all \n",
    "# others are represented by 'other'\n",
    "df2['relationship_topics'] = np.where(df2.topic_name.isin(relationships), df2.topic_name, 'other')\n",
    "\n",
    "# drop anything that isn't a relationship topic\n",
    "df2 = df2.loc[df2['relationship_topics'] != 'other']\n",
    "df2.groupby('decade').relationship_topics.value_counts(normalize = True).unstack().plot(kind = 'line')\n",
    "plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0.)\n",
    "plt.title('')\n",
    "plt.xlabel('Decade of Song')\n",
    "plt.xticks(rotation = 25)\n",
    "plt.ylabel('% of Songs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby('relationship_topics').resample('2Y').size().unstack(0)\\\n",
    "                                  .apply(lambda row: row / row.sum(), axis=1).plot(kind = 'line')\n",
    "# move the legend outside\n",
    "plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "def relationship_line(df):\n",
    "    # create a variable that stores a list relationship topics\n",
    "    relationships = ['affection','breakups','love', \n",
    "                     'sex', 'heartache', 'jealousy']\n",
    "    # make a copy\n",
    "    df2 = df.copy()\n",
    "    df2 = df2.set_index('date')\n",
    "    # add a column to the dataframe where any topic that is a relationship topic is gathered and all \n",
    "    # others are represented by 'other'\n",
    "    df2['relationship_topics'] = np.where(df2.topic_name.isin(relationships), df2.topic_name, 'other')\n",
    "    # drop anything that isn't a relationship topic\n",
    "    df2 = df2.loc[df2['relationship_topics'] != 'other']\n",
    "    ax = df2.groupby('relationship_topics').resample('Y').size().unstack(0).rolling(5).mean()\\\n",
    "                                      .apply(lambda row: row / row.sum(), axis=1).plot(kind = 'line', linewidth = 3)\n",
    "    # move the legend outside\n",
    "    plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0.)\n",
    "    plt.xlim(pd.to_datetime('1960'), pd.to_datetime('2021'))\n",
    "#     plt.ylim()\n",
    "    plt.title('Prevalence of Relationship Topics in Lyrics')\n",
    "    plt.xlabel('Year')\n",
    "    plt.xticks(rotation = 25)\n",
    "    plt.ylabel('Percentage of Songs')\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=None, symbol='%', is_latex=False))\n",
    "    plt.show()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28fbee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_line(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440048b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Billboard Colors\n",
    "def relationship_line(df):\n",
    "    # create a variable that stores a list relationship topics\n",
    "    relationships = ['affection','breakups','love', \n",
    "                     'sex', 'heartache', 'jealousy']\n",
    "    my_cmap = ListedColormap([\n",
    "    '#fc9d1c', #(orange)    \n",
    "    '#1f1e1b', #(black)\n",
    "    '#2dace4', #(blue)\n",
    "    '#fbdb08', #(yellow)        \n",
    "    '#69b138', #(green)\n",
    "    '#ec1c34', #(red)\n",
    "    ])\n",
    "    # make a copy\n",
    "    df2 = df.copy()\n",
    "    df2 = df2.set_index('date')\n",
    "    # add a column to the dataframe where any topic that is a relationship topic is gathered and all \n",
    "    # others are represented by 'other'\n",
    "    df2['relationship_topics'] = np.where(df2.topic_name.isin(relationships), df2.topic_name, 'other')\n",
    "    # drop anything that isn't a relationship topic\n",
    "    df2 = df2.loc[df2['relationship_topics'] != 'other']\n",
    "    ax = df2.groupby('relationship_topics').resample('Y').size().unstack(0).rolling(5).mean()\\\n",
    "                                      .apply(lambda row: row / row.sum(), axis=1).plot(kind = 'line', linewidth = 3, cmap = my_cmap)\n",
    "    # move the legend outside\n",
    "    plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0., prop={'size': 15})\n",
    "    plt.xlim(pd.to_datetime('1960'), pd.to_datetime('2021'))\n",
    "#     plt.ylim()\n",
    "    plt.title('Prevalence of Relationship Topics in Lyrics', fontsize = 20)\n",
    "    plt.xlabel('Year', fontsize = 18)\n",
    "    plt.xticks(rotation = 25, fontsize = 14)\n",
    "    plt.ylabel('Percentage of Songs', fontsize = 18)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=None, symbol='%', is_latex=False))\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_line(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebc7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df.copy()\n",
    "# train3 = train3.sample(3_000)\n",
    "df7['affection_v_sex'] = np.where(df7['topic_name'].isin(['good vibes', 'nature', 'americana','youth', 'dance', \n",
    "                 'transcendental', 'holiday', 'spanish']), df7['topic_name'], \n",
    "                                                None)\n",
    "ax = sns.swarmplot(data = df7, x = 'affection_v_sex', y = 'date')\n",
    "ax.set(title = 'Occurence of More Positive Topics')\n",
    "plt.ylabel('Date')\n",
    "plt.xlabel('Topic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "def relationships_swarm(df):  \n",
    "    df5 = df.copy()\n",
    "    df5['relationship_topics'] = np.where(df5['topic_name'].isin(['affection','love', 'sex', \n",
    "                                                         'heartache', 'jealousy','breakups']), df5['topic_name'], None)\n",
    "    ax = sns.swarmplot(data = df5, x = 'relationship_topics', y = 'date')\n",
    "    ax.set(title = '\\'Breakup\\' and \\'Love\\' Songs Have A Consistent Presence Over The Decades\\nWhile It Appears \\'Affection\\' And \\'Sex\\' Show A Trade-off')\n",
    "    plt.ylabel('Decades')\n",
    "    plt.xlabel('Relationship Topics')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d9244",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships_swarm(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf66073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Billboard Colors\n",
    "def relationships_swarm(df):  \n",
    "    df5 = df.copy()\n",
    "    df5['relationship_topics'] = np.where(df5['topic_name'].isin(['affection','love', 'sex', \n",
    "                                                         'heartache', 'jealousy','breakups']), df5['topic_name'], None)\n",
    "    ax = sns.swarmplot(data = df5, x = 'relationship_topics', y = 'date', palette = palette)\n",
    "    ax.set(title = '\\'Breakup\\' and \\'Love\\' Songs Have A Consistent Presence Over The Decades\\nWhile It Appears \\'Affection\\' And \\'Sex\\' Show A Trade-off')\n",
    "    plt.ylabel('Decades')\n",
    "    plt.xlabel('Relationship Topics')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0232ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships_swarm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "def touch_swarm(df):  \n",
    "    df6 = df.copy()\n",
    "    # train3 = train3.sample(3_000)\n",
    "    df6['affection_v_sex'] = np.where(df6['topic_name'].isin(['affection','sex']), df6['topic_name'], \n",
    "                                                    None)\n",
    "    ax = sns.swarmplot(data = df6, x = 'affection_v_sex', y = 'date')\n",
    "    ax.set(title = '\\'Affection\\' Has Been Replaced By More Explicit \\'Sex\\' Lyrics')\n",
    "    plt.ylabel('Date')\n",
    "    plt.xlabel('Topic')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4236a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "touch_swarm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ebe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Billboard Colors\n",
    "def touch_swarm(df):  \n",
    "    palette = [\n",
    "    '#ec1c34', #(red)\n",
    "    '#fc9d1c', #(orange)\n",
    "#   '#2dace4', #(blue)\n",
    "#   '#fbdb08', #(yellow)\n",
    "#   '#69b138' #(green)\n",
    "              ]\n",
    "    df6 = df.copy()\n",
    "    # train3 = train3.sample(3_000)\n",
    "    df6['affection_v_sex'] = np.where(df6['topic_name'].isin(['affection','sex']), df6['topic_name'], \n",
    "                                                    None)\n",
    "    ax = sns.swarmplot(data = df6, x = 'affection_v_sex', y = 'date', palette = palette)\n",
    "    plt.title('\\'Affection\\' Has Been Replaced By More Explicit \\'Sex\\' Lyrics', fontsize = 20)\n",
    "#     plt.title(fontsize = 20)\n",
    "    plt.ylabel('Date', fontsize = 18)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.xlabel('Topic', fontsize = 18)\n",
    "    plt.xticks(fontsize = 14)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c644507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_swarm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vice_bar(df):   \n",
    "    # create a variable that stores a list relationship topics\n",
    "    vices = ['sex', 'money', 'violence']\n",
    "    # make a copy\n",
    "    df3 = df.copy()\n",
    "    # add a column to the dataframe where any topic that is a vices topic is gathered and all \n",
    "    # others are represented by 'other'\n",
    "    df3['vice_topics'] = np.where(df3.topic_name.isin(vices), df3.topic_name, 'other')\n",
    "    # drop anything that isn't a relationship topic\n",
    "    df3 = df3.loc[df3['vice_topics'] != 'other']\n",
    "    df3.groupby('decade').topic_name.value_counts(normalize = True).unstack().plot(kind = 'bar', width = 1, ec = 'black')\n",
    "    plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0.)\n",
    "    plt.title('Vice Topics\\' Prevalence Over the Decades')\n",
    "    plt.xlabel('Decade of Song')\n",
    "    plt.xticks(rotation = 25)\n",
    "    plt.ylabel('Song Topic Count')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449337f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vice_bar(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vice_bar(df): \n",
    "    # create a variable that stores a list relationship topics\n",
    "    vices = ['sex', 'money', 'violence']\n",
    "    # make a copy\n",
    "    df3 = df.copy()\n",
    "    # add a column to the dataframe where any topic that is a vices topic is gathered and all \n",
    "    # others are represented by 'other'\n",
    "    df3['vice_topics'] = np.where(df3.topic_name.isin(vices), df3.topic_name, 'other')\n",
    "    # drop anything that isn't a relationship topic\n",
    "    df3 = df3.loc[df3['vice_topics'] != 'other']\n",
    "    df3.groupby('decade').topic_name.value_counts(normalize = True).unstack().plot(kind = 'bar', colormap = cmap, width = 1, ec = 'black')\n",
    "    plt.legend(bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0.)\n",
    "    plt.title('Vice Topics\\' Prevalence Over the Decades')\n",
    "    plt.xlabel('Decade of Song')\n",
    "    plt.xticks(rotation = 25)\n",
    "    plt.ylabel('Song Topic Count')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70448d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vice_bar(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original\n",
    "def vice_swarm(df):\n",
    "    df4 = df.copy()\n",
    "    # train3 = train3.sample(3_000)\n",
    "    df4['vices'] = np.where(df4['topic_name'].isin(['sex', 'money', 'violence']), df4['topic_name'], \n",
    "                                                    None)\n",
    "    ax = sns.swarmplot(data = df4, x = 'vices', y = 'date')\n",
    "    plt.title('Vice Topics Have Increased Significantly Beginning In The 90\\'s', fontsize = 20)\n",
    "    plt.ylabel('Decades',fontsize = 18)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.xlabel('Top 3 \\'Vice\\' Topics',fontsize = 18)\n",
    "    plt.xticks(fontsize = 14)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d92ffb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vice_swarm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c5da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Billboard Colors\n",
    "def vice_swarm(df):\n",
    "    palette = [\n",
    "    '#ec1c34', #(red)\n",
    "#   '#fc9d1c', #(orange)\n",
    "    '#2dace4', #(blue)\n",
    "#   '#fbdb08', #(yellow)\n",
    "    '#69b138' #(green)\n",
    "    ]\n",
    "    df4 = df.copy()\n",
    "    # train3 = train3.sample(3_000)\n",
    "    df4['vices'] = np.where(df4['topic_name'].isin(['sex', 'money', 'violence']), df4['topic_name'], \n",
    "                                                    None)\n",
    "    ax = sns.swarmplot(data = df4, x = 'vices', y = 'date', palette = palette)\n",
    "    plt.title('Vice Topics Have Increased Significantly Beginning In The 90\\'s', fontsize = 20)\n",
    "    plt.ylabel('Decades',fontsize = 18)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.xlabel('Top 3 \\'Vice\\' Topics',fontsize = 18)\n",
    "    plt.xticks(fontsize = 14)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e30ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vice_swarm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ca9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the Spearman's Rank Correlation Test\n",
    "from scipy.stats import chi2_contingency as chi2\n",
    "df4 = df.copy()\n",
    "df4['vices'] = np.where(df4['topic_name'].isin(['sex', 'money', 'violence']), df4['topic_name'], None)\n",
    "alpha = .05                                                    \n",
    "data1 = df4.vices\n",
    "data2 = df4.decade\n",
    "stat, p = chi2(data1, data2)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p <= alpha:\n",
    "    print('Reject NULL HYPOTHESIS') \n",
    "else: \n",
    "    print('ACCEPT NULL HYPOTHESIS') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef6080f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
